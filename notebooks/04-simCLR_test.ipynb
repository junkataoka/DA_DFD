{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'DA_DFD'\n",
      "/data/home/jkataok1/DA_DFD\n"
     ]
    }
   ],
   "source": [
    "%cd DA_DFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/jkataok1/mlenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.signal import spectrogram\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from collections import OrderedDict\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torch.utils.data as Data\n",
    "import wandb\n",
    "\n",
    "sys.path.append(\"/data/home/jkataok1/DA_DFD\")\n",
    "\n",
    "from src.dataloader import generate_dataset\n",
    "from src.ast_models import ASTModel\n",
    "from src.helper import count_batch_on_large_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: False, AudioSet pretraining: False\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=5\n",
      "copy v.cls_token\n",
      "copy v.pos_embed\n",
      "copy v.dist_token\n",
      "copy v.patch_embed.proj.weight\n",
      "copy v.patch_embed.proj.bias\n",
      "copy v.blocks.0.norm1.weight\n",
      "copy v.blocks.0.norm1.bias\n",
      "copy v.blocks.0.attn.qkv.weight\n",
      "copy v.blocks.0.attn.qkv.bias\n",
      "copy v.blocks.0.attn.proj.weight\n",
      "copy v.blocks.0.attn.proj.bias\n",
      "copy v.blocks.0.norm2.weight\n",
      "copy v.blocks.0.norm2.bias\n",
      "copy v.blocks.0.mlp.fc1.weight\n",
      "copy v.blocks.0.mlp.fc1.bias\n",
      "copy v.blocks.0.mlp.fc2.weight\n",
      "copy v.blocks.0.mlp.fc2.bias\n",
      "copy v.blocks.1.norm1.weight\n",
      "copy v.blocks.1.norm1.bias\n",
      "copy v.blocks.1.attn.qkv.weight\n",
      "copy v.blocks.1.attn.qkv.bias\n",
      "copy v.blocks.1.attn.proj.weight\n",
      "copy v.blocks.1.attn.proj.bias\n",
      "copy v.blocks.1.norm2.weight\n",
      "copy v.blocks.1.norm2.bias\n",
      "copy v.blocks.1.mlp.fc1.weight\n",
      "copy v.blocks.1.mlp.fc1.bias\n",
      "copy v.blocks.1.mlp.fc2.weight\n",
      "copy v.blocks.1.mlp.fc2.bias\n",
      "copy v.blocks.2.norm1.weight\n",
      "copy v.blocks.2.norm1.bias\n",
      "copy v.blocks.2.attn.qkv.weight\n",
      "copy v.blocks.2.attn.qkv.bias\n",
      "copy v.blocks.2.attn.proj.weight\n",
      "copy v.blocks.2.attn.proj.bias\n",
      "copy v.blocks.2.norm2.weight\n",
      "copy v.blocks.2.norm2.bias\n",
      "copy v.blocks.2.mlp.fc1.weight\n",
      "copy v.blocks.2.mlp.fc1.bias\n",
      "copy v.blocks.2.mlp.fc2.weight\n",
      "copy v.blocks.2.mlp.fc2.bias\n",
      "copy v.blocks.3.norm1.weight\n",
      "copy v.blocks.3.norm1.bias\n",
      "copy v.blocks.3.attn.qkv.weight\n",
      "copy v.blocks.3.attn.qkv.bias\n",
      "copy v.blocks.3.attn.proj.weight\n",
      "copy v.blocks.3.attn.proj.bias\n",
      "copy v.blocks.3.norm2.weight\n",
      "copy v.blocks.3.norm2.bias\n",
      "copy v.blocks.3.mlp.fc1.weight\n",
      "copy v.blocks.3.mlp.fc1.bias\n",
      "copy v.blocks.3.mlp.fc2.weight\n",
      "copy v.blocks.3.mlp.fc2.bias\n",
      "copy v.blocks.4.norm1.weight\n",
      "copy v.blocks.4.norm1.bias\n",
      "copy v.blocks.4.attn.qkv.weight\n",
      "copy v.blocks.4.attn.qkv.bias\n",
      "copy v.blocks.4.attn.proj.weight\n",
      "copy v.blocks.4.attn.proj.bias\n",
      "copy v.blocks.4.norm2.weight\n",
      "copy v.blocks.4.norm2.bias\n",
      "copy v.blocks.4.mlp.fc1.weight\n",
      "copy v.blocks.4.mlp.fc1.bias\n",
      "copy v.blocks.4.mlp.fc2.weight\n",
      "copy v.blocks.4.mlp.fc2.bias\n",
      "copy v.blocks.5.norm1.weight\n",
      "copy v.blocks.5.norm1.bias\n",
      "copy v.blocks.5.attn.qkv.weight\n",
      "copy v.blocks.5.attn.qkv.bias\n",
      "copy v.blocks.5.attn.proj.weight\n",
      "copy v.blocks.5.attn.proj.bias\n",
      "copy v.blocks.5.norm2.weight\n",
      "copy v.blocks.5.norm2.bias\n",
      "copy v.blocks.5.mlp.fc1.weight\n",
      "copy v.blocks.5.mlp.fc1.bias\n",
      "copy v.blocks.5.mlp.fc2.weight\n",
      "copy v.blocks.5.mlp.fc2.bias\n",
      "copy v.blocks.6.norm1.weight\n",
      "copy v.blocks.6.norm1.bias\n",
      "copy v.blocks.6.attn.qkv.weight\n",
      "copy v.blocks.6.attn.qkv.bias\n",
      "copy v.blocks.6.attn.proj.weight\n",
      "copy v.blocks.6.attn.proj.bias\n",
      "copy v.blocks.6.norm2.weight\n",
      "copy v.blocks.6.norm2.bias\n",
      "copy v.blocks.6.mlp.fc1.weight\n",
      "copy v.blocks.6.mlp.fc1.bias\n",
      "copy v.blocks.6.mlp.fc2.weight\n",
      "copy v.blocks.6.mlp.fc2.bias\n",
      "copy v.blocks.7.norm1.weight\n",
      "copy v.blocks.7.norm1.bias\n",
      "copy v.blocks.7.attn.qkv.weight\n",
      "copy v.blocks.7.attn.qkv.bias\n",
      "copy v.blocks.7.attn.proj.weight\n",
      "copy v.blocks.7.attn.proj.bias\n",
      "copy v.blocks.7.norm2.weight\n",
      "copy v.blocks.7.norm2.bias\n",
      "copy v.blocks.7.mlp.fc1.weight\n",
      "copy v.blocks.7.mlp.fc1.bias\n",
      "copy v.blocks.7.mlp.fc2.weight\n",
      "copy v.blocks.7.mlp.fc2.bias\n",
      "copy v.blocks.8.norm1.weight\n",
      "copy v.blocks.8.norm1.bias\n",
      "copy v.blocks.8.attn.qkv.weight\n",
      "copy v.blocks.8.attn.qkv.bias\n",
      "copy v.blocks.8.attn.proj.weight\n",
      "copy v.blocks.8.attn.proj.bias\n",
      "copy v.blocks.8.norm2.weight\n",
      "copy v.blocks.8.norm2.bias\n",
      "copy v.blocks.8.mlp.fc1.weight\n",
      "copy v.blocks.8.mlp.fc1.bias\n",
      "copy v.blocks.8.mlp.fc2.weight\n",
      "copy v.blocks.8.mlp.fc2.bias\n",
      "copy v.blocks.9.norm1.weight\n",
      "copy v.blocks.9.norm1.bias\n",
      "copy v.blocks.9.attn.qkv.weight\n",
      "copy v.blocks.9.attn.qkv.bias\n",
      "copy v.blocks.9.attn.proj.weight\n",
      "copy v.blocks.9.attn.proj.bias\n",
      "copy v.blocks.9.norm2.weight\n",
      "copy v.blocks.9.norm2.bias\n",
      "copy v.blocks.9.mlp.fc1.weight\n",
      "copy v.blocks.9.mlp.fc1.bias\n",
      "copy v.blocks.9.mlp.fc2.weight\n",
      "copy v.blocks.9.mlp.fc2.bias\n",
      "copy v.blocks.10.norm1.weight\n",
      "copy v.blocks.10.norm1.bias\n",
      "copy v.blocks.10.attn.qkv.weight\n",
      "copy v.blocks.10.attn.qkv.bias\n",
      "copy v.blocks.10.attn.proj.weight\n",
      "copy v.blocks.10.attn.proj.bias\n",
      "copy v.blocks.10.norm2.weight\n",
      "copy v.blocks.10.norm2.bias\n",
      "copy v.blocks.10.mlp.fc1.weight\n",
      "copy v.blocks.10.mlp.fc1.bias\n",
      "copy v.blocks.10.mlp.fc2.weight\n",
      "copy v.blocks.10.mlp.fc2.bias\n",
      "copy v.blocks.11.norm1.weight\n",
      "copy v.blocks.11.norm1.bias\n",
      "copy v.blocks.11.attn.qkv.weight\n",
      "copy v.blocks.11.attn.qkv.bias\n",
      "copy v.blocks.11.attn.proj.weight\n",
      "copy v.blocks.11.attn.proj.bias\n",
      "copy v.blocks.11.norm2.weight\n",
      "copy v.blocks.11.norm2.bias\n",
      "copy v.blocks.11.mlp.fc1.weight\n",
      "copy v.blocks.11.mlp.fc1.bias\n",
      "copy v.blocks.11.mlp.fc2.weight\n",
      "copy v.blocks.11.mlp.fc2.bias\n",
      "copy v.norm.weight\n",
      "copy v.norm.bias\n",
      "copy v.head.weight\n",
      "copy v.head.bias\n",
      "copy v.head_dist.weight\n",
      "copy v.head_dist.bias\n",
      "copy mlp_head.0.weight\n",
      "copy mlp_head.0.bias\n",
      "copy mlp_head.1.weight\n",
      "copy mlp_head.1.bias\n"
     ]
    }
   ],
   "source": [
    "model = ASTModel(label_dim=4, input_tdim=65, input_fdim=18, imagenet_pretrain=False, audioset_pretrain=False)\n",
    "checkpoint = \"/data/home/jkataok1/DA_DFD/src_models/CWRU_all_spectrogram_IMS_0_spectrogram_src_ast.pth\"\n",
    "\n",
    "state_dict_temp = torch.load(checkpoint)\n",
    "model_params = model.state_dict()\n",
    "for name, param in state_dict_temp.items():\n",
    "    if name in model_params:\n",
    "        model_params[name].copy_(param)\n",
    "        print(\"copy {}\".format(name), sep=\"\\r\")\n",
    "    else:\n",
    "        print(\"skip {}\".format(name), sep=\"\\r\")\n",
    "model.load_state_dict(state_dict_temp, strict=True)\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        # add mlp projection head\n",
    "        embedding_size = 1024\n",
    "\n",
    "        mlp_dim= model.mlp_head[-1].in_features\n",
    "        self.projection = nn.Sequential(\n",
    "           nn.Linear(in_features=mlp_dim, out_features=mlp_dim),\n",
    "           nn.BatchNorm1d(mlp_dim),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(in_features=mlp_dim, out_features=embedding_size),\n",
    "           nn.BatchNorm1d(embedding_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.projection(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model.mlp_head=Identity()\n",
    "model = model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "   \"\"\"\n",
    "   Vanilla Contrastive loss, also called InfoNceLoss as in SimCLR paper\n",
    "   \"\"\"\n",
    "   def __init__(self, batch_size, temperature=0.5):\n",
    "       super().__init__()\n",
    "       self.batch_size = batch_size\n",
    "       self.temperature = temperature\n",
    "       self.mask = (~torch.eye(batch_size * 2, batch_size * 2, dtype=bool)).float()\n",
    "\n",
    "   def device_as(self, t1, t2):\n",
    "        \"\"\"\n",
    "        Moves t1 to the device of t2\n",
    "        \"\"\"\n",
    "        return t1.to(t2.device)\n",
    "\n",
    "   def calc_similarity_batch(self, a, b):\n",
    "       representations = torch.cat([a, b], dim=0)\n",
    "       return F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
    "\n",
    "   def forward(self, proj_1, proj_2):\n",
    "       \"\"\"\n",
    "       proj_1 and proj_2 are batched embeddings [batch, embedding_dim]\n",
    "       where corresponding indices are pairs\n",
    "       z_i, z_j in the SimCLR paper\n",
    "       \"\"\"\n",
    "       batch_size = proj_1.shape[0]\n",
    "       z_i = F.normalize(proj_1, p=2, dim=1)\n",
    "       z_j = F.normalize(proj_2, p=2, dim=1)\n",
    "\n",
    "       similarity_matrix = self.calc_similarity_batch(z_i, z_j)\n",
    "\n",
    "       sim_ij = torch.diag(similarity_matrix, batch_size)\n",
    "       sim_ji = torch.diag(similarity_matrix, -batch_size)\n",
    "\n",
    "       positives = torch.cat([sim_ij, sim_ji], dim=0)\n",
    "\n",
    "       nominator = torch.exp(positives / self.temperature)\n",
    "\n",
    "       denominator = self.device_as(self.mask, similarity_matrix) * torch.exp(similarity_matrix / self.temperature)\n",
    "\n",
    "       all_losses = -torch.log(nominator / torch.sum(denominator, dim=1))\n",
    "       loss = torch.sum(all_losses) / (2 * self.batch_size)\n",
    "       return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augment:\n",
    "   \"\"\"\n",
    "   A stochastic data augmentation module\n",
    "   Transforms any given data example randomly\n",
    "   resulting in two correlated views of the same example,\n",
    "   denoted x ̃i and x ̃j, which we consider as a positive pair.\n",
    "   \"\"\"\n",
    "\n",
    "   def __init__(self, img_size, s=1):\n",
    "       color_jitter = T.ColorJitter(\n",
    "           0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s\n",
    "       )\n",
    "       # 10% of the image\n",
    "       blur = T.GaussianBlur(1, (0.1, 2.0))\n",
    "\n",
    "       self.train_transform = torch.nn.Sequential(\n",
    "           T.RandomResizedCrop(size=img_size),\n",
    "           T.RandomHorizontalFlip(p=0.5),  # with 0.5 probability\n",
    "           T.RandomApply([color_jitter], p=0.8),\n",
    "           T.RandomApply([blur], p=0.5),\n",
    "           #T.RandomGrayscale(p=0.2),\n",
    "           # imagenet stats\n",
    "           #T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "       )\n",
    "\n",
    "   def __call__(self, x):\n",
    "       return self.train_transform(x), self.train_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_param_groups(model, weight_decay, optimizer_name):\n",
    "   def exclude_from_wd_and_adaptation(name):\n",
    "       if 'bn' in name:\n",
    "           return True\n",
    "       if optimizer_name == 'lars' and 'bias' in name:\n",
    "           return True\n",
    "\n",
    "   param_groups = [\n",
    "       {\n",
    "           'params': [p for name, p in model.named_parameters() if not exclude_from_wd_and_adaptation(name)],\n",
    "           'weight_decay': weight_decay,\n",
    "           'layer_adaptation': True,\n",
    "       },\n",
    "       {\n",
    "           'params': [p for name, p in model.named_parameters() if exclude_from_wd_and_adaptation(name)],\n",
    "           'weight_decay': 0.,\n",
    "           'layer_adaptation': False,\n",
    "       },\n",
    "   ]\n",
    "   return param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pn725xu0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▅▅█▆▁▇█▇█▇</td></tr><tr><td>loss_src</td><td>▂▂▂▁▁▄█▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>2.38381</td></tr><tr><td>loss_src</td><td>6.07791</td></tr><tr><td>loss_tar</td><td>None.Tensor.item</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">/data/home/jkataok1/DA_DFD/log/SimCLR_01</strong> at: <a href='https://wandb.ai/junkataoka/DA_DFD/runs/pn725xu0' target=\"_blank\">https://wandb.ai/junkataoka/DA_DFD/runs/pn725xu0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230812_181608-pn725xu0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pn725xu0). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/home/jkataok1/DA_DFD/wandb/run-20230812_181643-81rhipm0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/junkataoka/DA_DFD/runs/81rhipm0' target=\"_blank\">/data/home/jkataok1/DA_DFD/log/SimCLR_01</a></strong> to <a href='https://wandb.ai/junkataoka/DA_DFD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/junkataoka/DA_DFD' target=\"_blank\">https://wandb.ai/junkataoka/DA_DFD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/junkataoka/DA_DFD/runs/81rhipm0' target=\"_blank\">https://wandb.ai/junkataoka/DA_DFD/runs/81rhipm0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/junkataoka/DA_DFD/runs/81rhipm0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2aac8ee87fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.0001\n",
    "weight_decay = 1e-4\n",
    "params= define_param_groups(model, weight_decay=weight_decay, optimizer_name=\"Adam\")\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "batch_size = 128*2  # Set the batch size that fits into your GPU\n",
    "epochs = 200\n",
    "temperature = 0.5\n",
    "loss = ContrastiveLoss(batch_size, temperature=temperature)\n",
    "\n",
    "src_dataset, tar_dataset = generate_dataset(\"/data/home/jkataok1/DA_DFD/data/processed\",\n",
    "                    \"CWRU\", \"IMS\", \"all_spectrogram\", \"0_spectrogram\")\n",
    "src_dataloader = Data.DataLoader(src_dataset, \n",
    "                                    batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "tar_dataloader = Data.DataLoader(tar_dataset,\n",
    "                                    batch_size=batch_size, shuffle=True, drop_last=True) \n",
    "\n",
    "hyperparameter_defaults = dict(\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    lr=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    ")\n",
    "log = \"/data/home/jkataok1/DA_DFD/log/SimCLR_01\"\n",
    "if not os.path.isdir(log):\n",
    "    os.makedirs(log)\n",
    "    print(\"create new log directory\")   \n",
    "model_name = \"SimCLR.pth\"\n",
    "wandb.init(config=hyperparameter_defaults, name=log, project=\"DA_DFD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:pvuohr0n) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▅▅▁▆▅▃▃▆▅█▄▁</td></tr><tr><td>loss_src</td><td>█▅▂▅▅▅▅██▇▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>2.21141</td></tr><tr><td>loss_src</td><td>5.60705</td></tr><tr><td>loss_tar</td><td>None.Tensor.item</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">/data/home/jkataok1/DA_DFD/log/SimCLR_01</strong> at: <a href='https://wandb.ai/junkataoka/DA_DFD/runs/pvuohr0n' target=\"_blank\">https://wandb.ai/junkataoka/DA_DFD/runs/pvuohr0n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230812_181527-pvuohr0n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:pvuohr0n). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/home/jkataok1/DA_DFD/wandb/run-20230812_181608-pn725xu0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/junkataoka/DA_DFD/runs/pn725xu0' target=\"_blank\">/data/home/jkataok1/DA_DFD/log/SimCLR_01</a></strong> to <a href='https://wandb.ai/junkataoka/DA_DFD' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/junkataoka/DA_DFD' target=\"_blank\">https://wandb.ai/junkataoka/DA_DFD</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/junkataoka/DA_DFD/runs/pn725xu0' target=\"_blank\">https://wandb.ai/junkataoka/DA_DFD/runs/pn725xu0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iter: 8, Loss: 2.3938214778900146\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10358/2115929344.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m                \"loss_tar\": loss_tar.item})\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mloss_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mloss_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlenv/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mlenv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_count = count_batch_on_large_dataset(src_dataloader, tar_dataloader)\n",
    "# count total iteration\n",
    "num_itern_total = epochs * batch_count\n",
    "# initialize epoch\n",
    "epoch = 0\n",
    "count_itern_each_epoch = 0\n",
    "best_acc = 0.0\n",
    "accum_iter = 5\n",
    "augmentation = Augment(img_size=(65, 18))\n",
    "best_loss = 1e+10\n",
    "model.train()\n",
    "\n",
    "for itern in range(num_itern_total):\n",
    "    src_train_batch = enumerate(src_dataloader)\n",
    "    tar_train_batch = enumerate(tar_dataloader)\n",
    "\n",
    "    if (itern==0 or count_itern_each_epoch==batch_count):\n",
    "        if itern != 0:\n",
    "            count_itern_each_epoch = 0\n",
    "            epoch += 1\n",
    "    \n",
    "    try:\n",
    "        (src_idx, src_input, src_target) = src_train_batch.__next__()[1]\n",
    "    except StopIteration:\n",
    "        src_train_batch = enumerate(src_dataloader)\n",
    "        (src_idx, src_input, src_target) = src_train_batch.__next__()[1]\n",
    "\n",
    "    try:\n",
    "        (tar_idx, tar_input, tar_target) = tar_train_batch.__next__()[1]\n",
    "    except StopIteration:\n",
    "        tar_train_batch = enumerate(tar_dataloader)\n",
    "        (tar_idx, tar_input, tar_target) = tar_train_batch.__next__()[1]\n",
    "\n",
    "    src_input_extend = src_input.unsqueeze(1).cuda()\n",
    "    tar_input_extend = tar_input.unsqueeze(1).cuda()\n",
    "\n",
    "    src_input_1, src_input_2 = augmentation(src_input_extend)\n",
    "    tar_input_1, tar_input_2 = augmentation(tar_input_extend)  \n",
    "\n",
    "    src_z_1 = model(src_input_1.squeeze(1))\n",
    "    src_z_2 = model(src_input_2.squeeze(1))\n",
    "    loss_src = loss(src_z_1, src_z_2)\n",
    "\n",
    "    tar_z_1 = model(tar_input_1.squeeze(1))\n",
    "    tar_z_2 = model(tar_input_2.squeeze(1))\n",
    "    loss_tar = loss(tar_z_1, tar_z_2)\n",
    "    loss_all = (loss_src + loss_tar) / accum_iter\n",
    "    wandb.log({\"loss\": loss_all.item(),\n",
    "               \"loss_src\": loss_src.item(),\n",
    "               \"loss_tar\": loss_tar.item()})\n",
    "    \n",
    "    loss_all.backward()\n",
    "    \n",
    "    if loss_all.item() < best_loss:\n",
    "        torch.save(model.state_dict(), os.path.join(log, model_name))\n",
    "        best_loss = loss_all.item()\n",
    "\n",
    "    print(\"Epoch: {}, Iter: {}, Loss: {}\".format(epoch, count_itern_each_epoch, loss_all.item()), end=\"\\t\")   \n",
    "\n",
    "    if itern % accum_iter == 0:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    count_itern_each_epoch += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
